\chapter{Обзор научно-технических источников информации} 

Реализация программного сервиса, связанного с обучаемыми цифровыми аватарами,
невозможна без опоры на современные научно-технические достижения
в области веб-разработки, распределённых вычислений,
хранения и обработки мультимедийных данных, а также технологий машинного обучения.
В данном разделе рассматриваются ключевые архитектурные и инфраструктурные решения,
а также программные компоненты, позволяющие реализовать сервис на практике.

\section{Концептуальные и архитектурные решения}
\subsection{Общий архитектурный паттерн. Микросервисный и монолитный подходы}

В качестве базового архитектурного паттерна
для дипломного проекта был выбран микросервисный подход.
Данный выбор обусловлен спецификой разрабатываемого приложения,
которое представляет собой комплексный сервис
с явно выраженными отдельными функциональными модулями:
интерфейсом взаимодействия с пользователями,
модулем генерации текстовых и аудиоответов,
процессом обучения моделей,
а также системой хранения и управления данными.

Микросервисная архитектура позволяет эффективно
распределить обязанности между компонентами,
разрабатывать их независимо друг от друга
и проводить параллельную работу над проектом в рамках команды.

Кроме того, такой подход значительно упрощает
процессы масштабирования.
При росте нагрузки можно увеличивать ресурсы
только для тех компонентов,
которые в этом нуждаются,
не затрагивая остальную систему.

В качестве альтернативы можно было бы рассмотреть монолитную архитектуру,
предполагающую разработку всех функций сервиса
в рамках единого приложения.
Несмотря на относительную простоту реализации на начальных этапах,
монолитное приложение имеет ряд существенных ограничений:
усложняется внесение изменений,
требующих частых релизов,
и масштабирование становится менее гибким,
так как масштабируется весь монолит целиком,
а не отдельные его части.

Кроме того, использование микросервисов упрощает
интеграцию различных технологий и фреймворков,
что особенно важно в контексте дипломного проекта,
в котором задействованы разнообразные инструменты и подходы,
такие как NLP и TTS модели,
брокеры сообщений и несколько видов баз данных.

Таким образом, микросервисная архитектура обеспечивает
необходимую гибкость, отказоустойчивость,
возможность масштабирования отдельных компонентов
и параллельную разработку в рамках команды,
что делает её оптимальным выбором в рамках дипломной разработки.

\subsection{Паттерн взаимодействия микросервисов. Хореография и оркестрация}

При построении взаимодействия между микросервисами
в рамках дипломного проекта был выбран паттерн оркестрации.
Он предполагает наличие централизованного компонента — оркестратора,
который управляет потоками данных и координирует вызовы
между отдельными модулями системы.

Такой подход хорошо подходит для систем,
в которых важна наблюдаемость,
чёткое управление последовательностью операций,
а также необходимость логирования состояния на каждом этапе обработки.

Альтернативным решением могла бы быть хореография,
где каждый микросервис действует автономно,
реагируя на события, опубликованные другими сервисами,
и самостоятельно принимая решения о своей логике работы.
Хореография более гибка и масштабируема
в условиях loosely coupled-сервисов,
однако она увеличивает сложность отладки,
снижает прозрачность процессов
и требует высокой зрелости всей архитектуры.

В контексте данного дипломного проекта,
где важны управляемость процессов,
централизованная маршрутизация запросов,
а также простота расширения и логирования,
паттерн оркестрации оказался более подходящим.

Он позволяет точно определять,
в какой момент вызывается тот или иной модуль,
а также централизованно обрабатывать ошибки
и реализовывать управление зависимостями между компонентами.

Таким образом, выбор в пользу оркестрации
обеспечивает необходимый баланс между контролем,
гибкостью и надёжностью при построении архитектуры сервиса
в рамках дипломной работы.

\subsection{Модель взаимодействия компонентов. Асинхронность, параллельность и конкурентность}

Одним из ключевых архитектурных решений
в рамках дипломной разработки стало использование асинхронного взаимодействия
между компонентами системы.
Данный подход был выбран с учётом природы выполняемых задач,
в частности генерации текстов и синтеза речи,
которые требуют значительных вычислительных ресурсов
и занимают заметное время на выполнение.

Асинхронная модель позволяет выполнять такие задачи
в фоновом режиме, не блокируя основной поток обработки,
и даёт возможность пользователю
продолжать взаимодействие с системой,
в том числе с другими аватарами,
не дожидаясь завершения ресурсоёмких операций.

Для лучшего понимания выбора архитектурной модели
необходимо кратко рассмотреть отличия между
асинхронностью, параллельностью и конкурентностью.
Асинхронность — это способ организации кода,
при котором выполнение может быть приостановлено и возобновлено позже,
что особенно эффективно в условиях операций ввода-вывода (I/O).
Параллельность же подразумевает физическое исполнение
нескольких задач одновременно, как правило — на разных ядрах процессора.
Конкурентность — более широкое понятие,
обозначающее возможность выполнения нескольких задач,
не обязательно параллельно,
но с чередованием выполнения или асинхронным управлением.

Асинхронное исполнение часто реализуется в виде событийного цикла,
в то время как параллельное — через многопоточность или многопроцессность.
Последние требуют более сложной координации и синхронизации,
что затрудняет масштабирование и отладку,
особенно в распределённой архитектуре.

В отличие от синхронного исполнения,
где каждый компонент ожидает завершения предыдущего действия,
асинхронный подход обеспечивает
более высокую отзывчивость и масштабируемость сервиса.
Синхронные вызовы проще в реализации,
но в условиях высоких задержек
или большого количества параллельных запросов
они ведут к блокировке потоков и снижению общей производительности.

Параллельное исполнение с использованием многопоточности
могло бы частично компенсировать блокировки,
однако такая реализация сложнее в обслуживании
и, забегая вперёд, стоит отметить,
что в случае с Python (язык будет подробнее рассмотрен в следующем разделе)
данный подход дополнительно осложняется ограничениями, связанными с GIL (Global Interpreter Lock),
характерным для языка программирования Python, технический выбор которого будет обоснован в последующих разделах.
Кроме того, в контексте работы с языковыми и звуковыми моделями
важно учитывать, что генерация занимает значительное время на GPU,
и в условиях параллельного запуска таких операций
быстро наступает исчерпание доступных ресурсов,
что приводит либо к очередям, либо к отказам в обработке.

Асинхронная модель позволяет более эффективно
распределять ресурсы между задачами,
обрабатывая запросы по мере готовности моделей к генерации,
а не блокируя систему в ожидании ответа от перегруженного компонента.

Таким образом, выбор асинхронного взаимодействия
в рамках дипломного проекта продиктован особенностями предполагаемой нагрузки:
интенсивные операции генерации и обучения,
непредсказуемое время отклика,
высокая параллельность пользовательских запросов
и необходимость устойчивой обработки в условиях
сетевой неопределённости и ограниченных вычислительных ресурсов.

\subsection{Модель хранения данных}
В рамках дипломной разработки рассматриваемый сервис
взаимодействует с принципиально разными типами данных,
что требует осознанного выбора подходящих систем хранения.
Ключевым источником анализа стал труд \cite{DataIntenciveDesign},
в котором систематизированы подходы к выбору хранилищ
в зависимости от характера данных и типов нагрузки.

Первым типом данных являются структурированные сущности:
информация о пользователях, профилях и параметрах аватаров,
чат-сессиях, настройках и доступах.
Для этих целей была выбрана реляционная база данных,
которая обеспечивает консистентность, связность данных
и мощный язык запросов (SQL), необходимый для аналитических задач
и построения сложных фильтров.
Альтернативой могли бы выступать документо-ориентированные СУБД,
например MongoDB, однако в данном случае
иерархическая структура с чёткими отношениями между таблицами
оказалась более подходящей.

Вторым важным типом данных являются
большие бинарные объекты — аудио- и видеоматериалы,
загружаемые пользователями для обучения аватаров.
Хранение таких файлов в реляционной базе данных
представляется неэффективным с точки зрения производительности и масштабирования.
Для этих целей было выбрано объектное хранилище,
поддерживающее интерфейс S3,
что обеспечивает совместимость с индустриальными инструментами
и удобство масштабируемого хранения.
Возможными альтернативами могли бы быть файловые хранилища
или blob-хранилища в рамках SQL-СУБД,
однако они уступают по скорости доступа,
гибкости маршрутизации и отказоустойчивости.

Наконец, особую категорию составляют
внутренние технические данные — журналы событий, логи ошибок,
статистика работы сервисов.
Эти данные имеют потоковую природу
и требуют быстрого добавления и поиска по ключу.
Для этих целей используется key-value-хранилище,
оптимизированное под работу с большим объёмом логов в режиме реального времени.
Альтернативой могла бы быть файловая система
или хранение логов в PostgreSQL,
но это создаёт избыточную нагрузку и снижает общую отзывчивость системы.

Таким образом, комбинация трёх типов хранилищ —
реляционного, объектного и ключ-значение —
обеспечивает логическую и техническую оптимальность решения задачи хранения
в условиях разнородных данных и разнообразных сценариев их использования.

\subsection{Паттерн клиентской архитектуры. Модели MPA и SPA}

В качестве модели клиентской части приложения был выбран паттерн SPA (Single Page Application), который предполагает 
однократную загрузку основного интерфейса и последующую динамическую подгрузку данных через API без полной перезагрузки 
страницы.

Выбор данного подхода обусловлен необходимостью обеспечить высокую отзывчивость и непрерывность пользовательского 
взаимодействия, особенно в условиях частых обращений к функциональности, связанной с управлением аватарами и обменом 
сообщениями в режиме реального времени. Такой сценарий требует гибкой клиентской логики и быстрого отклика интерфейса, что 
достигается за счёт исключения циклов полной перерисовки страницы.

Фронтенд построен с опорой на современные принципы реактивного взаимодействия, реализованные средствами, не требующими 
использования тяжёлых фреймворков. Это позволило упростить архитектуру, сохранить единообразие технологического стека и 
сократить затраты времени на разработку — особенно актуальные факторы в условиях ограниченных ресурсов дипломного проекта.

Альтернативой SPA могла бы стать модель MPA (Multi Page Application), при которой каждое взаимодействие пользователя приводит 
к загрузке новой страницы с серверным рендерингом содержимого. Несмотря на простоту реализации, данный подход менее эффективен 
в сценариях, требующих высокой интерактивности и поддержки многосессионного взаимодействия.

Таким образом, архитектура SPA была выбрана как наиболее подходящая, обеспечивая баланс между 
интерактивностью пользовательского интерфейса и эффективностью разработки.

\section{Программные средства и технологии реализации}
\subsection{Выбор языка программирования}

Ключевым техническим решением в рамках дипломной разработки
стал выбор языка программирования Python
в качестве основного инструмента для реализации серверной логики.

Python был выбран по совокупности следующих причин:
широкая поддержка асинхронного программирования,
богатая экосистема библиотек для работы с данными,
интеграция с фреймворками машинного обучения,
а также высокая читаемость и скорость разработки,
что особенно важно в условиях ограниченного времени и ресурсов.

Дополнительно, наличие развитых средств работы
с языковыми и звуковыми моделями (таких как библиотеки HuggingFace,
Transformers, Torchaudio и др.) делает Python
естественным выбором для построения сервисов,
основанных на обработке естественного языка и синтезе речи.

В качестве возможных альтернатив могли бы рассматриваться
языки с более высокой производительностью — например, Go или Rust,
однако в контексте дипломного проекта ключевым критерием
является не максимальная эффективность исполнения,
а возможность быстрой реализации, прототипирования и интеграции
с существующими ML-инструментами.

Кроме того, Python активно используется в академической среде,
что облегчает повторяемость, демонстрацию и возможное масштабирование решения
в дальнейшем, в том числе на инфраструктуре облачных сервисов,
таких как Google Colab, Kaggle.

Выбор Python, таким образом, органично вписывается
в общую архитектуру разрабатываемого сервиса:
его асинхронная модель исполнения сочетается
с выбранным серверным фреймворком и системой обмена сообщениями,
а гибкость и выразительность языка
позволяют эффективно реализовать как управляющую логику,
так и интеграцию с компонентами машинного обучения.

\subsection{Веб интерфейс}

При выборе технологии для реализации веб-интерфейса
в рамках настоящей выпускной квалификационной работы
решающее значение имели два основных аспекта:
ограниченный опыт участников команды
с использованием современных JavaScript-фреймворков
и стремление к технологической унификации проекта
с использованием единого языка программирования.

Исходя из этих условий, было принято решение
о выборе библиотеки FastHTML, написанной на языке Python,
которая предоставляет средства для генерации HTML-разметки
и интеграции с библиотекой HTMX.
Последняя представляет собой лёгкую JavaScript-библиотеку,
позволяющую динамически обновлять отдельные элементы страницы
посредством асинхронных HTTP-запросов,
исключая необходимость полной перезагрузки веб-страницы.

Подобное техническое решение позволило обеспечить
интерактивность пользовательского интерфейса
без привлечения более сложных и ресурсоёмких клиентских фреймворков,
что существенно упростило процессы разработки и последующего сопровождения.
Минималистичный подход к реализации веб-интерфейса
особенно оправдан в контексте проекта,
где основное внимание уделяется реализации серверной логики,
интеграции моделей машинного обучения и обработки данных.

В качестве альтернативы рассматривалась возможность использования
современных клиентских фреймворков, таких как React, Vue или Angular.
Несмотря на их обширные функциональные возможности
и развитую экосистему, применение данных инструментов
требовало бы освоения специфических технологий (например, JSX, шаблоны Vue),
создания дополнительной инфраструктуры сборки и управления зависимостями,
что существенно усложнило бы архитектуру и повысило нагрузку на разработчиков.

Дополнительным недостатком использования таких решений
стало бы неизбежное разделение проекта
на две отдельные части (клиентскую и серверную),
требующие различных инструментов, языков и процессов интеграции,
что негативно повлияло бы на простоту сопровождения
и целостность проекта в условиях ограниченных ресурсов
и учебной специфики работы.

Таким образом, выбор технологии FastHTML в сочетании с HTMX
представляется наиболее целесообразным в рамках данной работы,
обеспечивая оптимальное сочетание интерактивности интерфейса
и простоты разработки и сопровождения.

\subsection{Серверная часть. Оркестратор}

В основе серверной архитектуры дипломного проекта
лежит компонент-оркестратор, реализованный на базе библиотеки FastAPI \cite{Fastapi}.
Выбор FastAPI был обусловлен рядом преимуществ,
ключевыми среди которых являются высокая производительность
и полная поддержка асинхронного исполнения,
что обеспечивает эффективную обработку большого количества одновременных запросов
в условиях интенсивной сетевой и вычислительной нагрузки.

В качестве альтернативных решений рассматривались
популярные серверные фреймворки Django REST Framework и Flask.
Однако оба решения ориентированы преимущественно
на синхронную модель исполнения,
что делает их менее подходящими в контексте проекта,
где значительная часть операций связана с взаимодействием
между микросервисами и внешними асинхронными источниками данных.

В частности, Flask отличается простотой и минимализмом,
но требует дополнительных усилий при построении масштабируемой архитектуры,
а также не обладает встроенными средствами интеграции
с асинхронной обработкой, что ограничивает его применимость
в высоконагруженных распределённых системах.

Django REST Framework, в свою очередь,
является мощным и функциональным инструментом,
но его асинхронные возможности находятся на этапе развития
и не позволяют достичь той же степени гибкости и производительности,
которую предоставляет FastAPI.

Кроме того, важным преимуществом FastAPI является
отсутствие жёстких ограничений на структуру проекта,
что позволяет свободно организовывать взаимодействие между модулями,
интегрировать внешние хранилища, брокеры сообщений
и другие инфраструктурные компоненты без необходимости
следовать строго заданной архитектурной модели.

Таким образом, использование FastAPI в качестве
основного инструмента реализации оркестратора
представляется наиболее обоснованным решением,
соответствующим требованиям производительности, масштабируемости
и гибкости, предъявляемым к современным микросервисным приложениям
в условиях дипломного проектирования.

\subsection{Серверная часть. Модуль работы с языковой и звуковой моделью}

Одним из ключевых компонентов серверной архитектуры
является модуль генерации, отвечающий за формирование текстовых и аудиоответов
в ходе взаимодействия пользователя с аватаром.
Модуль функционирует по асинхронной модели,
обеспечивая выполнение ресурсоёмких операций вне основного цикла обработки
и получая команды от оркестратора посредством брокера сообщений,
реализующего принцип FIFO (first in, first out).

В качестве основной технологической базы
для построения языковых и звуковых моделей
были выбраны открытые библиотеки и модели
из экосистемы HuggingFace \cite{HugginFaceTransformersLib}.
Данный выбор обусловлен высоким уровнем зрелости инструментов,
поддержкой современного стекa NLP и TTS-технологий,
а также наличием предварительно обученных моделей
и инфраструктуры для дообучения и тонкой настройки.

Одним из важнейших преимуществ HuggingFace
является открытость исходного кода и соблюдение
свободных лицензий, что позволяет исключить зависимость
от коммерческих поставщиков и обеспечивает возможность
развёртывания модели в полностью контролируемой среде.
Кроме того, использование данных инструментов
снижает финансовые издержки на этапе разработки
и делает проект более устойчивым к изменениям внешней среды.

В качестве альтернативных решений могли бы рассматриваться
облачные сервисы от крупных вендоров, таких как Google Cloud (Dialogflow, Text-to-Speech),
Amazon Web Services (Polly, Lex), Microsoft Azure и др.
Несмотря на высокую точность и удобство интеграции,
эти решения обладают рядом проблем, которые включают в себя ограниченную доступность в отдельных регионах,
зависимость от внешнего API, стоимость при масштабируемом использовании,
а также ограниченные возможности кастомизации моделей под специфические задачи.

В контексте настоящей дипломной работы,
где важны автономность, воспроизводимость и контроль над конфигурацией,
использование локальных open-source решений
представляется наиболее рациональным и перспективным подходом.

Одной из главных задач для реализации пайплайнов обучения и генерации является выбор языковой модели. Для оценки производительности различных вариантов LLM был выбран ряд общепринятых бенчмарков, которые позволяют объективно оценить способности моделей от задач на базовые знания и логику до качества диалога и мультиязычности. Определяющими стали:
\begin{itemize}
    \item MMLU (Massive Multitask Language Understanding) — бенчмарк, который включает задачи из 57 различных академических дисциплин \cite{Wang2024MMLUPro};
    \item Russian SuperGLUE — аналог англоязычного SuperGLUE адаптированный под русский язык, включающий в себя тесты на классификацию, парное сопоставление текстов, логические выводы и пр. \cite{Fenogenova2022RussianSuperGLUE};
    \item MERA (Multilingual Evaluation of Reasoning Abilities) — относительно новый бенчмарк, состоящий из 21 задания по разным навыкам модели. Он позволяет выявить, насколько хорошо модель справляется с выводами вне англоязычного контекста \cite{Fenogenova2024MERA};
    \item Chatbot Arena — представляет собой систему парных сравнений моделей, где пользователи выбирают между ответами двух анонимных систем, что позволяет выявить предпочтения людей в реальном общении \cite{Chiang2024ChatbotArena};
    \item LIBRA (Linguistically Informed Benchmark for Russian AI)  — оценивает качество LLM именно в контексте русского языка, проверяя на синтаксический анализ, морфологию, семантику и другое \cite{Xu2024Libra}.
\end{itemize}
Проанализировав общую картину по всем бенчмаркам было выделено три серии открытых языковых моделей, которые показали высокие показатели: LLaMA \cite{Grattafiori2024Llama3}, Mistral \cite{Jiang2023Mistral7B}, Qwen \cite{Yang2025Qwen3} и DeepSeek \cite{DeepSeekAI2025DeepSeekV3}, имеющий наивысшие оценки.
LLM семейства LLaMA, разработанные Meta AI, имеют хороший результат в задачах понимания контекста. Mistral обладает высокой эффективностью за счет своей компактности. Qwen, разработанная Alibaba Cloud, обладает высоким качеством генерации при относительно небольшом количестве параметров. Главным их преимуществом является открытая архитектура, что позволяет использовать их в пользовательских и научных проектах. Однако, важно отметить, что данные, на которых обучались эти модели, в основном ориентированы на английский язык, поэтому из-за наличия небольшого количества текста на других языках в их наборах обучающих данных их общая производительность имеет отрицательных эффект при генерации на русском.
Отдельно стоит выделить модель DeepSeek, которую разработала китайская группа исследователей. Несмотря на то, что она в своем обучающем датасете имеет преимущественно китайские и английские текста, ее архитектура и объем позволяют ей достигать лидирующих позиций в большинстве бенчмарков.
Русский язык является одним из наиболее ресурсоемких языков с точки зрения морфологии, синтаксиса и семантики, что требует от LLM языковой адаптации и богатого лингвистического представления в наборах данных. Для решения этой проблемы были разработаны MTS AI, GigaChat и YandexGPT, которые демонстрируют высокое качество генерации, превосходя своих флагманских конкурентов,
ориентированных на английский язык, в том, что касается обработки и генерации текста на русском, но имеют закрытый исходный код, что делает невозможность их использование в рамках научного проекта. Поэтому высокой популярностью пользуются открытые модели, среди которых можно выделить серии Saiga \cite{Gusev2025RULM}, ruGPT \cite{Zmitrovich2023RussianLMs}, ruadapt \cite{Tikhomirov2024LEP} и Vikhr \cite{Nikolich2024Vikhr}. Они были дообучены на базе лидирующих англоязычных LLM и дополнительно настроены для улучшения генерации и понимания текста именно в русскоязычном контексте.
В таблице \ref{tab:pingpong} представлены средние значения по бенчмарку PingPong \cite{Gusev2025PingPong}, оценивающим языковые модели в их способности поддерживать многораундовую беседу, сохраняя выбранную роль и персону. Как из нее видно LLM семейства Saiga входят в число лидеров, что делает ее оптимальным выбором для задачи генерации текста в речевом стиле конкретного человека.


\begin{table}[h!]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{|c|c|c|c|}
\hline
 Модель $\backslash$ PingPong бенчмарк & Average Score & Average Score \\
\hline
deepseek\_v3\_0324                 & 4.79±0.04 & 4.93 \\
\hline
deepseek\_v3               & 4.65±0.06 & 4.79 \\
\hline
	
sainemo\_remix\_12b               & 4.61±0.07 & 4.64 \\
\hline
saiga\_yandexgpt\_8b    & 4.69±0.05 & 4.71 \\
\hline
	
saiga\_nemo\_12b\_v3                 & 4.68±0.06 & 4.63 \\
\hline
mistral\_nemo\_vikhr\_dostoevsky\_slerp\_12b                   & 4.55±0.06 & 4.59 \\
\hline
saiga\_gemma3\_12b             & 4.73±0.07 & 4.74 \\
\hline
\end{tabular}
}
\caption{Сравнение моделей по бенчмарку PingPong}
\label{tab:pingpong}
\end{table}

\subsection{Серверная часть. Технология распознавания речи}
Для преобразования аудиоданных в текст в рамках пайплайна обучения использовалась модель автоматического распознавания речи Whisper, разработанная компанией Open AI \cite{Zhao2024WhisperPMFA}. Она является представителем open-source систем ASR (Automatic Speech Recognition), основанную на архитектуре трансформеров и обученную на большом объеме аудиоматериалов, включающих различные интервью, лекции, подкасты, видеоконтент. Благодаря этому Whisper хорошо справляется с переводом потенциальных источников информации для сбора датасета под конкретного человека.
В качестве альтернативных решений рассматривались облачные сервисы, такие как Google Speech-to-Text, однако их применение ограничено лицензионными условиями и необходимостью постоянного интернет-соединения. Кроме того, была проанализирована модель Wav2Vec 2.0 \cite{Baevski2020Wav2Vec2}, разработанная Facebook AI Research, которая демонстрирует высокую точность на английском языке, но требует дополнительного дообучения для русского, что значительно усложняет ее интеграцию в проект и увеличивает требования к вычислительным ресурсам.
Для извлечения аудиодорожки из видеофайлов выбрана библиотека MoviePy, которая имеет удобный и простой интерфейс, что упрощает процесс программной реализации данного этапа пайплайна. Данный модуль является удобной надстройкой над библиотекой FFmpeg, упрощая функции нарезки, конкатенации, преобразования форматов, обеспечивая высокий уровень абстракции. 



\subsection{Серверная часть. Брокер сообщений}

Для организации взаимодействия между микросервисами
в архитектуре дипломного проекта применяется брокер сообщений,
играющий ключевую роль в обеспечении асинхронной коммуникации
и устойчивости системы к пиковым нагрузкам.

В качестве основного инструмента был выбран Apache Kafka \cite{ApacheKafka},
широко распространённая распределённая платформа
для обработки потоков данных в реальном времени.
Kafka обеспечивает высокую пропускную способность,
гарантированную доставку сообщений,
а также масштабируемость за счёт распределённой архитектуры,
что делает её оптимальным решением для сервисов,
требующих надёжной и непрерывной передачи данных между компонентами.

Выбор Kafka также обоснован её зрелостью,
широкой поддержкой в сообществе и богатой документацией,
а также наличием опыта работы с данной системой в команде,
что позволило сократить время на внедрение и конфигурацию.

В качестве альтернатив могли бы быть использованы
RabbitMQ — брокер с поддержкой расширенных шаблонов маршрутизации сообщений,
или Memphis — более молодой, но активно развивающийся инструмент
с удобным интерфейсом и низким порогом входа.
Тем не менее, в условиях проекта, ориентированного на
обработку ресурсоёмких задач и высокую частоту межсервисных взаимодействий,
Kafka продемонстрировала наибольшую пригодность благодаря своей отказоустойчивости
и способности обрабатывать большие объёмы сообщений в режиме реального времени.

Таким образом, применение Apache Kafka
представляется технически обоснованным решением,
соответствующим требованиям надёжности, масштабируемости и производительности,
необходимым для устойчивой работы распределённого сервиса
в рамках дипломного проекта.

\subsection{Инфраструктура и развертывание}

Микросервисная архитектура, выбранная в рамках дипломной разработки,
предполагает наличие большого числа взаимосвязанных компонентов,
каждый из которых выполняет строго определённую функцию
и может развиваться независимо от остальных.
Такая модульность увеличивает гибкость и масштабируемость системы,
но одновременно усложняет процессы развертывания, настройки и сопровождения.

Для минимизации издержек на конфигурацию окружения и унификацию подходов
к развертыванию различных сервисов было принято решение
использовать технологию контейнеризации на основе Docker \cite{Docker}.
Docker предоставляет изолированную среду выполнения
для каждого из компонентов, позволяя гарантировать
одинаковое поведение приложений вне зависимости от целевой платформы.

Дополнительно применяется инструмент Docker Compose,
обеспечивающий декларативное описание всей системы
и автоматизацию процессов сборки, настройки и запуска сервисов
в едином командном интерфейсе.
Такой подход значительно упрощает работу с инфраструктурой
на этапе разработки, тестирования и демонстрации,
что особенно важно в условиях дипломного проектирования,
где критичны воспроизводимость и предсказуемость поведения среды.

В качестве альтернативы контейнеризации
могло бы рассматриваться использование виртуальных машин.
Однако данный подход предполагает более высокие накладные расходы,
меньшую гибкость в масштабировании
и требует отдельной настройки каждой инстанции системы,
что затрудняет управление и автоматизацию развёртывания.

Таким образом, применение Docker и связанных с ним инструментов
позволило выстроить устойчивую и удобную в сопровождении инфраструктуру,
оптимально подходящую для микросервисной архитектуры,
реализуемой в рамках дипломного проекта.

\subsection{Итог по архитектуре}

\begin{table}[h!]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{|p{3.3cm}|p{3.1cm}|p{3.3cm}|p{6.2cm}|}
\hline
\textbf{Область} & \textbf{Выбрано} & \textbf{Альтернативы} & \textbf{Ключевые аргументы выбора} \\
\hline
Архитектурный паттерн & Микросервисы & Монолит & 
Гибкое масштабирование по компонентам.
База для параллельной работы команды.
Упрощённая интеграция разнородных технологий \\
\hline
Взаимодействие микросервисов & Оркестрация & Хореография &
Требуется центральный контроль,
единый маршрутизатор запросов,
упрощённый контроль точек отказав \\
\hline
Модель исполнения & Асинхронность & Синхронность или многопоточность &
Высокая отзывчивость при I/O-нагрузке.
Нет затрат на синхронизацию потоков.
\\
\hline
Модель хранения & RDBMS + S3 Object Store + Key–Value & Только SQL.  Только NoSQL.  Локальная файловая система. &
Выбор нативно продиктован формой нагрузки
и видом данных для хранения.
Структурные данные в SQL.
Крупные бинарные объекты — в S3.
Логи и временные статусы — в KV-хранилище.
\\
\hline
Клиентская архитектура & SPA & MPA &
Непрерывный UX, частые
AJAX-запросы для диалогов.
\\ 
\hline
\end{tabular}
}
\caption{Архитектурные решения и обоснование выбора}
\end{table}


\begin{table}[h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{|p{3cm}|p{3.2cm}|p{3.3cm}|p{6cm}|}
\hline
\textbf{Компонент} &
\textbf{Технология} &
\textbf{Альтернативы} &
\textbf{Причины выбора} \\ \hline
Язык программирования & Python & Go &
Широкая экосистема 
как для веб-разработки
так и для ML
\\
\hline
Оркестратор (API) & FastAPI & Django REST (DRF), Flask &
Полноценный async.
Минимальные требования
к структуре проекта от фреймворка
\\
\hline
Модуль NLP / TTS & HuggingFace Transformers / TTS & Google Cloud TTS, Azure Cognitive, ElevenLabs&
Открытый код библиотек,
бесплатный доступ к необходимому 
спектру облачного функционала
\\
\hline
Брокер сообщений & Apache Kafka & RabbitMQ; Memphis &
Опыт работы с платформой,
так как в контексте работы
от брокера требуется базовый функционал 
\\
\hline
Веб-интерфейс & FastHTML + HTMX & React, Vue, Angular &
Единый язык проекта.
Отсутствие опыта у команды в работе с 
JS-фреймворками
\\
\hline
Развёртывание & Docker + Docker Compose & Виртуальные машины &
Унификация интерфейса для локальной разработки,
упрощенные условия для потенциального 
деплоя продукта
\\
\hline
\end{tabular}
}
\caption{Выбранный технологический стек и рассмотренные альтернативы}
\end{table}
